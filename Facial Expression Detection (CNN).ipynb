{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"../input/facial-expression/fer2013/\"))\n\n# Any results you write to the current directory are saved as output.","execution_count":30,"outputs":[{"output_type":"stream","text":"['fer2013.csv']\n","name":"stdout"}]},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true},"cell_type":"code","source":"import tensorflow as tf\n\nimport keras\nfrom keras.models import Sequential\nfrom keras.layers import Conv2D, MaxPooling2D, AveragePooling2D\nfrom keras.layers import Dense, Activation, Dropout, Flatten\n\nfrom keras.preprocessing import image\nfrom keras.preprocessing.image import ImageDataGenerator\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt","execution_count":31,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"87965c894d3b7f3b3dfc66d8c2a60efcc08a370d"},"cell_type":"code","source":"# get the data\nfilname = '../input/facial-expression/fer2013/fer2013.csv'\nlabel_map = ['Anger', 'Disgust', 'Fear', 'Happy', 'Sad', 'Surprise', 'Neutral']\nnames=['emotion','pixels','usage']\ndf=pd.read_csv('../input/facial-expression/fer2013/fer2013.csv',names=names, na_filter=False)\nim=df['pixels']\ndf.head(10)","execution_count":32,"outputs":[{"output_type":"execute_result","execution_count":32,"data":{"text/plain":"   emotion    ...        usage\n0  emotion    ...        Usage\n1        0    ...     Training\n2        0    ...     Training\n3        2    ...     Training\n4        4    ...     Training\n5        6    ...     Training\n6        2    ...     Training\n7        4    ...     Training\n8        3    ...     Training\n9        3    ...     Training\n\n[10 rows x 3 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>emotion</th>\n      <th>pixels</th>\n      <th>usage</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>emotion</td>\n      <td>pixels</td>\n      <td>Usage</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0</td>\n      <td>70 80 82 72 58 58 60 63 54 58 60 48 89 115 121...</td>\n      <td>Training</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0</td>\n      <td>151 150 147 155 148 133 111 140 170 174 182 15...</td>\n      <td>Training</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>2</td>\n      <td>231 212 156 164 174 138 161 173 182 200 106 38...</td>\n      <td>Training</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>4</td>\n      <td>24 32 36 30 32 23 19 20 30 41 21 22 32 34 21 1...</td>\n      <td>Training</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>6</td>\n      <td>4 0 0 0 0 0 0 0 0 0 0 0 3 15 23 28 48 50 58 84...</td>\n      <td>Training</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>2</td>\n      <td>55 55 55 55 55 54 60 68 54 85 151 163 170 179 ...</td>\n      <td>Training</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>4</td>\n      <td>20 17 19 21 25 38 42 42 46 54 56 62 63 66 82 1...</td>\n      <td>Training</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>3</td>\n      <td>77 78 79 79 78 75 60 55 47 48 58 73 77 79 57 5...</td>\n      <td>Training</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>3</td>\n      <td>85 84 90 121 101 102 133 153 153 169 177 189 1...</td>\n      <td>Training</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"metadata":{"trusted":true,"_uuid":"bfde4d91ff367dfa6764202c1b309ea291fb833a"},"cell_type":"code","source":"def getData(filname):\n    # images are 48x48\n    # N = 35887\n    Y = []\n    X = []\n    first = True\n    for line in open(filname):\n        if first:\n            first = False\n        else:\n            row = line.split(',')\n            Y.append(int(row[0]))\n            X.append([int(p) for p in row[1].split()])\n\n    X, Y = np.array(X) / 255.0, np.array(Y)\n    return X, Y\n","execution_count":33,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"435d0e06553e3de3fd982e4a4a86c28018ac3913"},"cell_type":"code","source":"X, Y = getData(filname)\nnum_class = len(set(Y))\nprint(num_class)","execution_count":34,"outputs":[{"output_type":"stream","text":"7\n","name":"stdout"}]},{"metadata":{"trusted":true,"_uuid":"f3c6bfb7aaf3c25ba7cdd5621e4d62b9eaa5502e"},"cell_type":"code","source":"# keras with tensorflow backend\nN, D = X.shape\nX = X.reshape(N, 48, 48, 1)","execution_count":35,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"be4faef86c3c5635697f10939547edd5c8760308"},"cell_type":"code","source":"from sklearn.model_selection import train_test_split\n\nX_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.1, random_state=10)\ny_train = (np.arange(num_class) == y_train[:, None]).astype(np.float32)\ny_test = (np.arange(num_class) == y_test[:, None]).astype(np.float32)","execution_count":36,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Cross Validation\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import KFold\nfrom sklearn.model_selection import RepeatedKFold\nkf = RepeatedKFold(n_splits=5, n_repeats=10, random_state=None) \n\nfor train_index, test_index in kf.split(X):\n      print(\"Train:\", train_index, \"Validation:\",test_index)\n      X_train, X_test = X[train_index], X[test_index] \n      y_train, y_test = Y[train_index], Y[test_index]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"3afd36886a65ff49fe48ac73271f7477b574375a"},"cell_type":"code","source":"from keras.models import Sequential\nfrom keras.layers import Dense , Activation , Dropout ,Flatten\nfrom keras.layers.convolutional import Conv2D\nfrom keras.layers.convolutional import MaxPooling2D\nfrom keras.metrics import categorical_accuracy\nfrom keras.models import model_from_json\nfrom keras.callbacks import ModelCheckpoint\nfrom keras.optimizers import *\nfrom keras.layers.normalization import BatchNormalization","execution_count":37,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Activation layer 'relu'"},{"metadata":{"trusted":true,"_uuid":"c8eaecce539d06c983ed73142ac1484dbfa5e970"},"cell_type":"code","source":"def my_model():\n    model = Sequential()\n    input_shape = (48,48,1)\n    model.add(Conv2D(64, (5, 5), input_shape=input_shape,activation='relu', padding='same'))\n    model.add(Conv2D(64, (5, 5), activation='relu', padding='same'))\n    model.add(BatchNormalization())\n    model.add(MaxPooling2D(pool_size=(2, 2)))\n\n    model.add(Conv2D(128, (5, 5),activation='relu',padding='same'))\n    model.add(Conv2D(128, (5, 5),activation='relu',padding='same'))\n    model.add(BatchNormalization())\n    model.add(MaxPooling2D(pool_size=(2, 2)))\n\n    model.add(Conv2D(256, (3, 3),activation='relu',padding='same'))\n    model.add(Conv2D(256, (3, 3),activation='relu',padding='same'))\n    model.add(BatchNormalization())\n    model.add(MaxPooling2D(pool_size=(2, 2)))\n    \n    model.add(Flatten())\n    model.add(Dense(128))\n    model.add(BatchNormalization())\n    model.add(Activation('relu'))\n    model.add(Dropout(0.2))\n    model.add(Dense(7))\n    model.add(Activation('softmax'))\n    \n    model.compile(loss='categorical_crossentropy', metrics=['accuracy'],optimizer='adam')\n    # UNCOMMENT THIS TO VIEW THE ARCHITECTURE\n    model.summary()\n    \n    return model\nmodel=my_model()\nmodel.summary()","execution_count":38,"outputs":[{"output_type":"stream","text":"_________________________________________________________________\nLayer (type)                 Output Shape              Param #   \n=================================================================\nconv2d_7 (Conv2D)            (None, 48, 48, 64)        1664      \n_________________________________________________________________\nconv2d_8 (Conv2D)            (None, 48, 48, 64)        102464    \n_________________________________________________________________\nbatch_normalization_5 (Batch (None, 48, 48, 64)        256       \n_________________________________________________________________\nmax_pooling2d_4 (MaxPooling2 (None, 24, 24, 64)        0         \n_________________________________________________________________\nconv2d_9 (Conv2D)            (None, 24, 24, 128)       204928    \n_________________________________________________________________\nconv2d_10 (Conv2D)           (None, 24, 24, 128)       409728    \n_________________________________________________________________\nbatch_normalization_6 (Batch (None, 24, 24, 128)       512       \n_________________________________________________________________\nmax_pooling2d_5 (MaxPooling2 (None, 12, 12, 128)       0         \n_________________________________________________________________\nconv2d_11 (Conv2D)           (None, 12, 12, 256)       295168    \n_________________________________________________________________\nconv2d_12 (Conv2D)           (None, 12, 12, 256)       590080    \n_________________________________________________________________\nbatch_normalization_7 (Batch (None, 12, 12, 256)       1024      \n_________________________________________________________________\nmax_pooling2d_6 (MaxPooling2 (None, 6, 6, 256)         0         \n_________________________________________________________________\nflatten_2 (Flatten)          (None, 9216)              0         \n_________________________________________________________________\ndense_3 (Dense)              (None, 128)               1179776   \n_________________________________________________________________\nbatch_normalization_8 (Batch (None, 128)               512       \n_________________________________________________________________\nactivation_3 (Activation)    (None, 128)               0         \n_________________________________________________________________\ndropout_2 (Dropout)          (None, 128)               0         \n_________________________________________________________________\ndense_4 (Dense)              (None, 7)                 903       \n_________________________________________________________________\nactivation_4 (Activation)    (None, 7)                 0         \n=================================================================\nTotal params: 2,787,015\nTrainable params: 2,785,863\nNon-trainable params: 1,152\n_________________________________________________________________\n_________________________________________________________________\nLayer (type)                 Output Shape              Param #   \n=================================================================\nconv2d_7 (Conv2D)            (None, 48, 48, 64)        1664      \n_________________________________________________________________\nconv2d_8 (Conv2D)            (None, 48, 48, 64)        102464    \n_________________________________________________________________\nbatch_normalization_5 (Batch (None, 48, 48, 64)        256       \n_________________________________________________________________\nmax_pooling2d_4 (MaxPooling2 (None, 24, 24, 64)        0         \n_________________________________________________________________\nconv2d_9 (Conv2D)            (None, 24, 24, 128)       204928    \n_________________________________________________________________\nconv2d_10 (Conv2D)           (None, 24, 24, 128)       409728    \n_________________________________________________________________\nbatch_normalization_6 (Batch (None, 24, 24, 128)       512       \n_________________________________________________________________\nmax_pooling2d_5 (MaxPooling2 (None, 12, 12, 128)       0         \n_________________________________________________________________\nconv2d_11 (Conv2D)           (None, 12, 12, 256)       295168    \n_________________________________________________________________\nconv2d_12 (Conv2D)           (None, 12, 12, 256)       590080    \n_________________________________________________________________\nbatch_normalization_7 (Batch (None, 12, 12, 256)       1024      \n_________________________________________________________________\nmax_pooling2d_6 (MaxPooling2 (None, 6, 6, 256)         0         \n_________________________________________________________________\nflatten_2 (Flatten)          (None, 9216)              0         \n_________________________________________________________________\ndense_3 (Dense)              (None, 128)               1179776   \n_________________________________________________________________\nbatch_normalization_8 (Batch (None, 128)               512       \n_________________________________________________________________\nactivation_3 (Activation)    (None, 128)               0         \n_________________________________________________________________\ndropout_2 (Dropout)          (None, 128)               0         \n_________________________________________________________________\ndense_4 (Dense)              (None, 7)                 903       \n_________________________________________________________________\nactivation_4 (Activation)    (None, 7)                 0         \n=================================================================\nTotal params: 2,787,015\nTrainable params: 2,785,863\nNon-trainable params: 1,152\n_________________________________________________________________\n","name":"stdout"}]},{"metadata":{"trusted":true,"_uuid":"5004be413385dbdf6c3967d34c59e541095ea667"},"cell_type":"code","source":"path_model='model_filter.h5' # save model at this location after each epoch\nK.tensorflow_backend.clear_session() # destroys the current graph and builds a new one\nmodel=my_model() # create the model\nK.set_value(model.optimizer.lr,1e-3) # set the learning rate\n# fit the model\nh=model.fit(x=X_train,     \n            y=y_train, \n            batch_size=64, \n            epochs=20, \n            verbose=1, \n            validation_data=(X_test,y_test),\n            shuffle=True,\n            callbacks=[\n                ModelCheckpoint(filepath=path_model),\n            ]\n            )","execution_count":39,"outputs":[{"output_type":"stream","text":"_________________________________________________________________\nLayer (type)                 Output Shape              Param #   \n=================================================================\nconv2d_1 (Conv2D)            (None, 48, 48, 64)        1664      \n_________________________________________________________________\nconv2d_2 (Conv2D)            (None, 48, 48, 64)        102464    \n_________________________________________________________________\nbatch_normalization_1 (Batch (None, 48, 48, 64)        256       \n_________________________________________________________________\nmax_pooling2d_1 (MaxPooling2 (None, 24, 24, 64)        0         \n_________________________________________________________________\nconv2d_3 (Conv2D)            (None, 24, 24, 128)       204928    \n_________________________________________________________________\nconv2d_4 (Conv2D)            (None, 24, 24, 128)       409728    \n_________________________________________________________________\nbatch_normalization_2 (Batch (None, 24, 24, 128)       512       \n_________________________________________________________________\nmax_pooling2d_2 (MaxPooling2 (None, 12, 12, 128)       0         \n_________________________________________________________________\nconv2d_5 (Conv2D)            (None, 12, 12, 256)       295168    \n_________________________________________________________________\nconv2d_6 (Conv2D)            (None, 12, 12, 256)       590080    \n_________________________________________________________________\nbatch_normalization_3 (Batch (None, 12, 12, 256)       1024      \n_________________________________________________________________\nmax_pooling2d_3 (MaxPooling2 (None, 6, 6, 256)         0         \n_________________________________________________________________\nflatten_1 (Flatten)          (None, 9216)              0         \n_________________________________________________________________\ndense_1 (Dense)              (None, 128)               1179776   \n_________________________________________________________________\nbatch_normalization_4 (Batch (None, 128)               512       \n_________________________________________________________________\nactivation_1 (Activation)    (None, 128)               0         \n_________________________________________________________________\ndropout_1 (Dropout)          (None, 128)               0         \n_________________________________________________________________\ndense_2 (Dense)              (None, 7)                 903       \n_________________________________________________________________\nactivation_2 (Activation)    (None, 7)                 0         \n=================================================================\nTotal params: 2,787,015\nTrainable params: 2,785,863\nNon-trainable params: 1,152\n_________________________________________________________________\nTrain on 32298 samples, validate on 3589 samples\nEpoch 1/20\n32298/32298 [==============================] - 16s 507us/step - loss: 1.6109 - acc: 0.3785 - val_loss: 1.7187 - val_acc: 0.3605\nEpoch 2/20\n32298/32298 [==============================] - 15s 450us/step - loss: 1.2489 - acc: 0.5268 - val_loss: 1.2805 - val_acc: 0.5118\nEpoch 3/20\n32298/32298 [==============================] - 15s 456us/step - loss: 1.0892 - acc: 0.5913 - val_loss: 1.2744 - val_acc: 0.5196\nEpoch 4/20\n32298/32298 [==============================] - 15s 469us/step - loss: 0.9757 - acc: 0.6374 - val_loss: 1.1137 - val_acc: 0.5768\nEpoch 5/20\n32298/32298 [==============================] - 15s 466us/step - loss: 0.8571 - acc: 0.6834 - val_loss: 1.1328 - val_acc: 0.5765\nEpoch 6/20\n32298/32298 [==============================] - 15s 456us/step - loss: 0.7214 - acc: 0.7357 - val_loss: 1.1341 - val_acc: 0.5993\nEpoch 7/20\n32298/32298 [==============================] - 14s 444us/step - loss: 0.5692 - acc: 0.7954 - val_loss: 1.2212 - val_acc: 0.5929\nEpoch 8/20\n32298/32298 [==============================] - 15s 451us/step - loss: 0.4178 - acc: 0.8534 - val_loss: 1.3183 - val_acc: 0.5996\nEpoch 9/20\n32298/32298 [==============================] - 15s 469us/step - loss: 0.2821 - acc: 0.9049 - val_loss: 1.4628 - val_acc: 0.5768\nEpoch 10/20\n32298/32298 [==============================] - 15s 465us/step - loss: 0.2134 - acc: 0.9272 - val_loss: 1.7137 - val_acc: 0.5993\nEpoch 11/20\n32298/32298 [==============================] - 14s 444us/step - loss: 0.1746 - acc: 0.9426 - val_loss: 1.6568 - val_acc: 0.5985\nEpoch 12/20\n32298/32298 [==============================] - 15s 450us/step - loss: 0.1389 - acc: 0.9561 - val_loss: 1.8866 - val_acc: 0.6018\nEpoch 13/20\n32298/32298 [==============================] - 15s 458us/step - loss: 0.1132 - acc: 0.9641 - val_loss: 1.9477 - val_acc: 0.5938\nEpoch 14/20\n32298/32298 [==============================] - 15s 454us/step - loss: 0.1126 - acc: 0.9634 - val_loss: 2.0054 - val_acc: 0.6069\nEpoch 15/20\n32298/32298 [==============================] - 15s 462us/step - loss: 0.1099 - acc: 0.9636 - val_loss: 2.2338 - val_acc: 0.5784\nEpoch 16/20\n32298/32298 [==============================] - 15s 455us/step - loss: 0.1048 - acc: 0.9656 - val_loss: 2.1869 - val_acc: 0.6060\nEpoch 17/20\n32298/32298 [==============================] - 15s 463us/step - loss: 0.0815 - acc: 0.9732 - val_loss: 2.2684 - val_acc: 0.5993\nEpoch 18/20\n32298/32298 [==============================] - 14s 447us/step - loss: 0.0756 - acc: 0.9752 - val_loss: 2.2901 - val_acc: 0.6110\nEpoch 19/20\n32298/32298 [==============================] - 15s 449us/step - loss: 0.0785 - acc: 0.9739 - val_loss: 2.0333 - val_acc: 0.6071\nEpoch 20/20\n32298/32298 [==============================] - 15s 452us/step - loss: 0.0850 - acc: 0.9715 - val_loss: 2.1796 - val_acc: 0.6046\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"def my_model():\n    model = Sequential()\n    input_shape = (48,48,1)\n    model.add(Conv2D(64, (5, 5), input_shape=input_shape,activation='relu', padding='same'))\n    model.add(Conv2D(64, (5, 5), activation='relu', padding='same'))\n    model.add(BatchNormalization())\n    model.add(MaxPooling2D(pool_size=(2, 2)))\n\n    model.add(Conv2D(128, (5, 5),activation='relu',padding='same'))\n    model.add(Conv2D(128, (5, 5),activation='relu',padding='same'))\n    model.add(BatchNormalization())\n    model.add(MaxPooling2D(pool_size=(2, 2)))\n\n    model.add(Flatten())\n    model.add(Dense(128))\n    model.add(BatchNormalization())\n    model.add(Activation('relu'))\n    model.add(Dropout(0.2))\n    model.add(Dense(7))\n    model.add(Activation('softmax'))\n    \n    model.compile(loss='categorical_crossentropy', metrics=['accuracy'],optimizer='adam')\n    # UNCOMMENT THIS TO VIEW THE ARCHITECTURE\n    model.summary()\n    \n    return model\nmodel=my_model()\nmodel.summary()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"path_model='model_filter2.h5' # save model at this location after each epoch\nK.tensorflow_backend.clear_session() # destroys the current graph and builds a new one\nmodel=my_model() # create the model\nK.set_value(model.optimizer.lr,1e-3) # set the learning rate\n# fit the model\nh=model.fit(x=X_train,     \n            y=y_train, \n            batch_size=64, \n            epochs=20, \n            verbose=1, \n            validation_data=(X_test,y_test),\n            shuffle=True,\n            callbacks=[\n                ModelCheckpoint(filepath=path_model),\n            ]\n            )","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Activation layer 'selu'"},{"metadata":{"trusted":true},"cell_type":"code","source":"def my_model2():\n    model = Sequential()\n    input_shape = (48,48,1)\n    model.add(Conv2D(64, (5, 5), input_shape=input_shape,activation='selu', padding='same'))\n    model.add(Conv2D(64, (5, 5), activation='selu', padding='same'))\n    model.add(BatchNormalization())\n    model.add(MaxPooling2D(pool_size=(2, 2)))\n\n    model.add(Conv2D(128, (5, 5),activation='selu',padding='same'))\n    model.add(Conv2D(128, (5, 5),activation='selu',padding='same'))\n    model.add(BatchNormalization())\n    model.add(MaxPooling2D(pool_size=(2, 2)))\n\n    model.add(Conv2D(256, (3, 3),activation='selu',padding='same'))\n    model.add(Conv2D(256, (3, 3),activation='selu',padding='same'))\n    model.add(BatchNormalization())\n    model.add(MaxPooling2D(pool_size=(2, 2)))\n\n    model.add(Flatten())\n    model.add(Dense(128))\n    model.add(BatchNormalization())\n    model.add(Activation('selu'))\n    model.add(Dropout(0.2))\n    model.add(Dense(7))\n    model.add(Activation('softmax'))\n    \n    model.compile(loss='categorical_crossentropy', metrics=['accuracy'],optimizer='adam')\n    # UNCOMMENT THIS TO VIEW THE ARCHITECTURE\n    #model.summary()\n    \n    return model\nmodel=my_model()\nmodel.summary()","execution_count":40,"outputs":[{"output_type":"stream","text":"_________________________________________________________________\nLayer (type)                 Output Shape              Param #   \n=================================================================\nconv2d_7 (Conv2D)            (None, 48, 48, 64)        1664      \n_________________________________________________________________\nconv2d_8 (Conv2D)            (None, 48, 48, 64)        102464    \n_________________________________________________________________\nbatch_normalization_5 (Batch (None, 48, 48, 64)        256       \n_________________________________________________________________\nmax_pooling2d_4 (MaxPooling2 (None, 24, 24, 64)        0         \n_________________________________________________________________\nconv2d_9 (Conv2D)            (None, 24, 24, 128)       204928    \n_________________________________________________________________\nconv2d_10 (Conv2D)           (None, 24, 24, 128)       409728    \n_________________________________________________________________\nbatch_normalization_6 (Batch (None, 24, 24, 128)       512       \n_________________________________________________________________\nmax_pooling2d_5 (MaxPooling2 (None, 12, 12, 128)       0         \n_________________________________________________________________\nconv2d_11 (Conv2D)           (None, 12, 12, 256)       295168    \n_________________________________________________________________\nconv2d_12 (Conv2D)           (None, 12, 12, 256)       590080    \n_________________________________________________________________\nbatch_normalization_7 (Batch (None, 12, 12, 256)       1024      \n_________________________________________________________________\nmax_pooling2d_6 (MaxPooling2 (None, 6, 6, 256)         0         \n_________________________________________________________________\nflatten_2 (Flatten)          (None, 9216)              0         \n_________________________________________________________________\ndense_3 (Dense)              (None, 128)               1179776   \n_________________________________________________________________\nbatch_normalization_8 (Batch (None, 128)               512       \n_________________________________________________________________\nactivation_3 (Activation)    (None, 128)               0         \n_________________________________________________________________\ndropout_2 (Dropout)          (None, 128)               0         \n_________________________________________________________________\ndense_4 (Dense)              (None, 7)                 903       \n_________________________________________________________________\nactivation_4 (Activation)    (None, 7)                 0         \n=================================================================\nTotal params: 2,787,015\nTrainable params: 2,785,863\nNon-trainable params: 1,152\n_________________________________________________________________\n_________________________________________________________________\nLayer (type)                 Output Shape              Param #   \n=================================================================\nconv2d_7 (Conv2D)            (None, 48, 48, 64)        1664      \n_________________________________________________________________\nconv2d_8 (Conv2D)            (None, 48, 48, 64)        102464    \n_________________________________________________________________\nbatch_normalization_5 (Batch (None, 48, 48, 64)        256       \n_________________________________________________________________\nmax_pooling2d_4 (MaxPooling2 (None, 24, 24, 64)        0         \n_________________________________________________________________\nconv2d_9 (Conv2D)            (None, 24, 24, 128)       204928    \n_________________________________________________________________\nconv2d_10 (Conv2D)           (None, 24, 24, 128)       409728    \n_________________________________________________________________\nbatch_normalization_6 (Batch (None, 24, 24, 128)       512       \n_________________________________________________________________\nmax_pooling2d_5 (MaxPooling2 (None, 12, 12, 128)       0         \n_________________________________________________________________\nconv2d_11 (Conv2D)           (None, 12, 12, 256)       295168    \n_________________________________________________________________\nconv2d_12 (Conv2D)           (None, 12, 12, 256)       590080    \n_________________________________________________________________\nbatch_normalization_7 (Batch (None, 12, 12, 256)       1024      \n_________________________________________________________________\nmax_pooling2d_6 (MaxPooling2 (None, 6, 6, 256)         0         \n_________________________________________________________________\nflatten_2 (Flatten)          (None, 9216)              0         \n_________________________________________________________________\ndense_3 (Dense)              (None, 128)               1179776   \n_________________________________________________________________\nbatch_normalization_8 (Batch (None, 128)               512       \n_________________________________________________________________\nactivation_3 (Activation)    (None, 128)               0         \n_________________________________________________________________\ndropout_2 (Dropout)          (None, 128)               0         \n_________________________________________________________________\ndense_4 (Dense)              (None, 7)                 903       \n_________________________________________________________________\nactivation_4 (Activation)    (None, 7)                 0         \n=================================================================\nTotal params: 2,787,015\nTrainable params: 2,785,863\nNon-trainable params: 1,152\n_________________________________________________________________\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"path_model='model_filter1.h5' # save model at this location after each epoch\nK.tensorflow_backend.clear_session() # destroys the current graph and builds a new one\nmodel=my_model() # create the model\nK.set_value(model.optimizer.lr,1e-3) # set the learning rate\n# fit the model\nh=model.fit(x=X_train,     \n            y=y_train, \n            batch_size=64, \n            epochs=20, \n            verbose=1, \n            validation_data=(X_test,y_test),\n            shuffle=True,\n            callbacks=[\n                ModelCheckpoint(filepath=path_model),\n            ]\n            )","execution_count":null,"outputs":[{"output_type":"stream","text":"_________________________________________________________________\nLayer (type)                 Output Shape              Param #   \n=================================================================\nconv2d_1 (Conv2D)            (None, 48, 48, 64)        1664      \n_________________________________________________________________\nconv2d_2 (Conv2D)            (None, 48, 48, 64)        102464    \n_________________________________________________________________\nbatch_normalization_1 (Batch (None, 48, 48, 64)        256       \n_________________________________________________________________\nmax_pooling2d_1 (MaxPooling2 (None, 24, 24, 64)        0         \n_________________________________________________________________\nconv2d_3 (Conv2D)            (None, 24, 24, 128)       204928    \n_________________________________________________________________\nconv2d_4 (Conv2D)            (None, 24, 24, 128)       409728    \n_________________________________________________________________\nbatch_normalization_2 (Batch (None, 24, 24, 128)       512       \n_________________________________________________________________\nmax_pooling2d_2 (MaxPooling2 (None, 12, 12, 128)       0         \n_________________________________________________________________\nconv2d_5 (Conv2D)            (None, 12, 12, 256)       295168    \n_________________________________________________________________\nconv2d_6 (Conv2D)            (None, 12, 12, 256)       590080    \n_________________________________________________________________\nbatch_normalization_3 (Batch (None, 12, 12, 256)       1024      \n_________________________________________________________________\nmax_pooling2d_3 (MaxPooling2 (None, 6, 6, 256)         0         \n_________________________________________________________________\nflatten_1 (Flatten)          (None, 9216)              0         \n_________________________________________________________________\ndense_1 (Dense)              (None, 128)               1179776   \n_________________________________________________________________\nbatch_normalization_4 (Batch (None, 128)               512       \n_________________________________________________________________\nactivation_1 (Activation)    (None, 128)               0         \n_________________________________________________________________\ndropout_1 (Dropout)          (None, 128)               0         \n_________________________________________________________________\ndense_2 (Dense)              (None, 7)                 903       \n_________________________________________________________________\nactivation_2 (Activation)    (None, 7)                 0         \n=================================================================\nTotal params: 2,787,015\nTrainable params: 2,785,863\nNon-trainable params: 1,152\n_________________________________________________________________\nTrain on 32298 samples, validate on 3589 samples\nEpoch 1/30\n32298/32298 [==============================] - 16s 488us/step - loss: 1.6638 - acc: 0.3545 - val_loss: 1.7761 - val_acc: 0.2862\nEpoch 2/30\n 4928/32298 [===>..........................] - ETA: 11s - loss: 1.4129 - acc: 0.4539","name":"stdout"}]},{"metadata":{"trusted":true,"_uuid":"0c7e2abb2a89f4df0d28de0a49db1f60c84fbcf0"},"cell_type":"code","source":"objects = ('angry', 'disgust', 'fear', 'happy', 'sad', 'surprise', 'neutral')\ny_pos = np.arange(len(objects))\nprint(y_pos)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"077d44e8bbb7549a09682eb09c417903bf2fd935"},"cell_type":"code","source":"def emotion_analysis(emotions):\n    objects = ['angry', 'disgust', 'fear', 'happy', 'sad', 'surprise', 'neutral']\n    y_pos = np.arange(len(objects))\n    plt.bar(y_pos, emotions, align='center', alpha=0.9)\n    plt.tick_params(axis='x', which='both', pad=10,width=4,length=10)\n    plt.xticks(y_pos, objects)\n    plt.ylabel('percentage')\n    plt.title('emotion')\n    \nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"241291244491cc1e84a45ecb0da66c1c09a4cd7a"},"cell_type":"code","source":"y_pred=model.predict(X_test)\n#print(y_pred)\ny_test.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"0e97d2cb00640d2bfc4d4de9456249e893f72cc2"},"cell_type":"code","source":"#import seaborn as sn\n#import pandas as pd\n#import matplotlib.pyplot as plt\n#import numpy as np\n#from sklearn.metrics import confusion_matrix\n#%matplotlib inline\n#cm = confusion_matrix(np.where(y_test == 1)[1], y_pred)\n#cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n#df_cm = pd.DataFrame(cm, index = [i for i in \"0123456\"],\n                  #columns = [i for i in \"0123456\"])\n#plt.figure(figsize = (20,15))\n#sn.heatmap(df_cm, annot=True)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Real Time Expression Prediction**"},{"metadata":{"trusted":true,"_uuid":"70fc48e66d18c54ba629e625ad8def5ad2d93fa6"},"cell_type":"code","source":"from skimage import io\nimg = image.load_img('../input/myimage/Shawon.jpg', grayscale=True, target_size=(48, 48))\nshow_img=image.load_img('../input/myimage/Shawon.jpg', grayscale=False, target_size=(200, 200))\nx = image.img_to_array(img)\nx = np.expand_dims(x, axis = 0)\n\nx /= 255\n\ncustom = model.predict(x)\n#print(custom[0])\nemotion_analysis(custom[0])\n\nx = np.array(x, 'float32')\nx = x.reshape([48, 48]);\n\nplt.gray()\nplt.imshow(show_img)\nplt.show()\n\nm=0.000000000000000000001\na=custom[0]\nfor i in range(0,len(a)):\n    if a[i]>m:\n        m=a[i]\n        ind=i\n        \nprint('Expression Prediction:',objects[ind])\n        ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"82db72b60f80eb18474bf880369791cf346c9749"},"cell_type":"code","source":"from skimage import io\nimg = image.load_img('../input/testimages/wallpaper2you_443897.jpg', grayscale=True, target_size=(48, 48))\nshow_img=image.load_img('../input/testimages/wallpaper2you_443897.jpg', grayscale=False, target_size=(200, 200))\nx = image.img_to_array(img)\nx = np.expand_dims(x, axis = 0)\n\nx /= 255\n\ncustom = model.predict(x)\n#print(custom[0])\nemotion_analysis(custom[0])\n\nx = np.array(x, 'float32')\nx = x.reshape([48, 48]);\n\nplt.gray()\nplt.imshow(show_img)\nplt.show()\n\nm=0.000000000000000000001\na=custom[0]\nfor i in range(0,len(a)):\n    if a[i]>m:\n        m=a[i]\n        ind=i\n        \nprint('Expression Prediction:',objects[ind])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Live Demo of Production Level Project**\n\n[Facial Expression Detection Web App](https://faceai.herokuapp.com/)"}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}