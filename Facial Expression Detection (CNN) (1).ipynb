{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"../input/facial-expression/fer2013/\"))\n\n# Any results you write to the current directory are saved as output.","execution_count":46,"outputs":[{"output_type":"stream","text":"['fer2013.csv']\n","name":"stdout"}]},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true},"cell_type":"code","source":"import tensorflow as tf\n\nimport keras\nfrom keras.models import Sequential\nfrom keras.layers import Conv2D, MaxPooling2D, AveragePooling2D\nfrom keras.layers import Dense, Activation, Dropout, Flatten\n\nfrom keras.preprocessing import image\nfrom keras.preprocessing.image import ImageDataGenerator\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt","execution_count":47,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"87965c894d3b7f3b3dfc66d8c2a60efcc08a370d"},"cell_type":"code","source":"# get the data\nfilname = '../input/facial-expression/fer2013/fer2013.csv'\nlabel_map = ['Anger', 'Disgust', 'Fear', 'Happy', 'Sad', 'Surprise', 'Neutral']\nnames=['emotion','pixels','usage']\ndf=pd.read_csv('../input/facial-expression/fer2013/fer2013.csv',names=names, na_filter=False)\nim=df['pixels']\ndf.head(10)","execution_count":48,"outputs":[{"output_type":"execute_result","execution_count":48,"data":{"text/plain":"   emotion    ...        usage\n0  emotion    ...        Usage\n1        0    ...     Training\n2        0    ...     Training\n3        2    ...     Training\n4        4    ...     Training\n5        6    ...     Training\n6        2    ...     Training\n7        4    ...     Training\n8        3    ...     Training\n9        3    ...     Training\n\n[10 rows x 3 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>emotion</th>\n      <th>pixels</th>\n      <th>usage</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>emotion</td>\n      <td>pixels</td>\n      <td>Usage</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0</td>\n      <td>70 80 82 72 58 58 60 63 54 58 60 48 89 115 121...</td>\n      <td>Training</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0</td>\n      <td>151 150 147 155 148 133 111 140 170 174 182 15...</td>\n      <td>Training</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>2</td>\n      <td>231 212 156 164 174 138 161 173 182 200 106 38...</td>\n      <td>Training</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>4</td>\n      <td>24 32 36 30 32 23 19 20 30 41 21 22 32 34 21 1...</td>\n      <td>Training</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>6</td>\n      <td>4 0 0 0 0 0 0 0 0 0 0 0 3 15 23 28 48 50 58 84...</td>\n      <td>Training</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>2</td>\n      <td>55 55 55 55 55 54 60 68 54 85 151 163 170 179 ...</td>\n      <td>Training</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>4</td>\n      <td>20 17 19 21 25 38 42 42 46 54 56 62 63 66 82 1...</td>\n      <td>Training</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>3</td>\n      <td>77 78 79 79 78 75 60 55 47 48 58 73 77 79 57 5...</td>\n      <td>Training</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>3</td>\n      <td>85 84 90 121 101 102 133 153 153 169 177 189 1...</td>\n      <td>Training</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"metadata":{"trusted":true,"_uuid":"bfde4d91ff367dfa6764202c1b309ea291fb833a"},"cell_type":"code","source":"def getData(filname):\n    # images are 48x48\n    # N = 35887\n    Y = []\n    X = []\n    first = True\n    for line in open(filname):\n        if first:\n            first = False\n        else:\n            row = line.split(',')\n            Y.append(int(row[0]))\n            X.append([int(p) for p in row[1].split()])\n\n    X, Y = np.array(X) / 255.0, np.array(Y)\n    return X, Y\n","execution_count":49,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"435d0e06553e3de3fd982e4a4a86c28018ac3913"},"cell_type":"code","source":"X, Y = getData(filname)\nnum_class = len(set(Y))\nprint(num_class)","execution_count":50,"outputs":[{"output_type":"stream","text":"7\n","name":"stdout"}]},{"metadata":{"trusted":true,"_uuid":"f3c6bfb7aaf3c25ba7cdd5621e4d62b9eaa5502e"},"cell_type":"code","source":"# keras with tensorflow backend\nN, D = X.shape\nX = X.reshape(N, 48, 48, 1)","execution_count":51,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"be4faef86c3c5635697f10939547edd5c8760308"},"cell_type":"code","source":"from sklearn.model_selection import train_test_split\n\nX_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.1, random_state=10)\ny_train = (np.arange(num_class) == y_train[:, None]).astype(np.float32)\ny_test = (np.arange(num_class) == y_test[:, None]).astype(np.float32)","execution_count":69,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\n","execution_count":71,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":72,"outputs":[{"output_type":"error","ename":"ValueError","evalue":"Found array with dim 4. Estimator expected <= 2.","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)","\u001b[0;32m<ipython-input-72-b75fa9280e61>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mclf\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mDecisionTreeClassifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mclf\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mclf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0my_predicted\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mclf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.6/site-packages/sklearn/tree/tree.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight, check_input, X_idx_sorted)\u001b[0m\n\u001b[1;32m    788\u001b[0m             \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    789\u001b[0m             \u001b[0mcheck_input\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcheck_input\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 790\u001b[0;31m             X_idx_sorted=X_idx_sorted)\n\u001b[0m\u001b[1;32m    791\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    792\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.6/site-packages/sklearn/tree/tree.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight, check_input, X_idx_sorted)\u001b[0m\n\u001b[1;32m    114\u001b[0m         \u001b[0mrandom_state\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_random_state\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom_state\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    115\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcheck_input\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 116\u001b[0;31m             \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mDTYPE\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maccept_sparse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"csc\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    117\u001b[0m             \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mensure_2d\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    118\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0missparse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.6/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_array\u001b[0;34m(array, accept_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, warn_on_dtype, estimator)\u001b[0m\n\u001b[1;32m    449\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mallow_nd\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0marray\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    450\u001b[0m             raise ValueError(\"Found array with dim %d. %s expected <= 2.\"\n\u001b[0;32m--> 451\u001b[0;31m                              % (array.ndim, estimator_name))\n\u001b[0m\u001b[1;32m    452\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mforce_all_finite\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    453\u001b[0m             \u001b[0m_assert_all_finite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mValueError\u001b[0m: Found array with dim 4. Estimator expected <= 2."]}]},{"metadata":{},"cell_type":"markdown","source":"# Cross Validation\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import KFold\nfrom sklearn.model_selection import RepeatedKFold\nkf = RepeatedKFold(n_splits=5, n_repeats=10, random_state=None) \n\nfor train_index, test_index in kf.split(X):\n      print(\"Train:\", train_index, \"Validation:\",test_index)\n      X_train, X_test = X[train_index], X[test_index] \n      y_train, y_test = Y[train_index], Y[test_index]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"3afd36886a65ff49fe48ac73271f7477b574375a"},"cell_type":"code","source":"from keras.models import Sequential\nfrom keras.layers import Dense , Activation , Dropout ,Flatten\nfrom keras.layers.convolutional import Conv2D\nfrom keras.layers.convolutional import MaxPooling2D\nfrom keras.metrics import categorical_accuracy\nfrom keras.models import model_from_json\nfrom keras.callbacks import ModelCheckpoint\nfrom keras.optimizers import *\nfrom keras.layers.normalization import BatchNormalization","execution_count":53,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Activation layer 'relu'"},{"metadata":{"trusted":true,"_uuid":"c8eaecce539d06c983ed73142ac1484dbfa5e970"},"cell_type":"code","source":"def my_model():\n    model = Sequential()\n    input_shape = (48,48,1)\n    model.add(Conv2D(64, (5, 5), input_shape=input_shape,activation='relu', padding='same'))\n    model.add(Conv2D(64, (5, 5), activation='relu', padding='same'))\n    model.add(BatchNormalization())\n    model.add(MaxPooling2D(pool_size=(2, 2)))\n\n    model.add(Conv2D(128, (5, 5),activation='relu',padding='same'))\n    model.add(Conv2D(128, (5, 5),activation='relu',padding='same'))\n    model.add(BatchNormalization())\n    model.add(MaxPooling2D(pool_size=(2, 2)))\n\n    model.add(Conv2D(256, (3, 3),activation='relu',padding='same'))\n    model.add(Conv2D(256, (3, 3),activation='relu',padding='same'))\n    model.add(BatchNormalization())\n    model.add(MaxPooling2D(pool_size=(2, 2)))\n    \n    model.add(Flatten())\n    model.add(Dense(128))\n    model.add(BatchNormalization())\n    model.add(Activation('relu'))\n    model.add(Dropout(0.2))\n    model.add(Dense(7))\n    model.add(Activation('softmax'))\n    \n    model.compile(loss='categorical_crossentropy', metrics=['accuracy'],optimizer='adam')\n    # UNCOMMENT THIS TO VIEW THE ARCHITECTURE\n    #model.summary()\n    \n    return model\nmodel=my_model()\nmodel.summary()","execution_count":55,"outputs":[{"output_type":"stream","text":"_________________________________________________________________\nLayer (type)                 Output Shape              Param #   \n=================================================================\nconv2d_13 (Conv2D)           (None, 48, 48, 64)        1664      \n_________________________________________________________________\nconv2d_14 (Conv2D)           (None, 48, 48, 64)        102464    \n_________________________________________________________________\nbatch_normalization_9 (Batch (None, 48, 48, 64)        256       \n_________________________________________________________________\nmax_pooling2d_7 (MaxPooling2 (None, 24, 24, 64)        0         \n_________________________________________________________________\nconv2d_15 (Conv2D)           (None, 24, 24, 128)       204928    \n_________________________________________________________________\nconv2d_16 (Conv2D)           (None, 24, 24, 128)       409728    \n_________________________________________________________________\nbatch_normalization_10 (Batc (None, 24, 24, 128)       512       \n_________________________________________________________________\nmax_pooling2d_8 (MaxPooling2 (None, 12, 12, 128)       0         \n_________________________________________________________________\nconv2d_17 (Conv2D)           (None, 12, 12, 256)       295168    \n_________________________________________________________________\nconv2d_18 (Conv2D)           (None, 12, 12, 256)       590080    \n_________________________________________________________________\nbatch_normalization_11 (Batc (None, 12, 12, 256)       1024      \n_________________________________________________________________\nmax_pooling2d_9 (MaxPooling2 (None, 6, 6, 256)         0         \n_________________________________________________________________\nflatten_3 (Flatten)          (None, 9216)              0         \n_________________________________________________________________\ndense_5 (Dense)              (None, 128)               1179776   \n_________________________________________________________________\nbatch_normalization_12 (Batc (None, 128)               512       \n_________________________________________________________________\nactivation_5 (Activation)    (None, 128)               0         \n_________________________________________________________________\ndropout_3 (Dropout)          (None, 128)               0         \n_________________________________________________________________\ndense_6 (Dense)              (None, 7)                 903       \n_________________________________________________________________\nactivation_6 (Activation)    (None, 7)                 0         \n=================================================================\nTotal params: 2,787,015\nTrainable params: 2,785,863\nNon-trainable params: 1,152\n_________________________________________________________________\n","name":"stdout"}]},{"metadata":{"trusted":true,"_uuid":"5004be413385dbdf6c3967d34c59e541095ea667"},"cell_type":"code","source":"path_model='model_filter.h5' # save model at this location after each epoch\nK.tensorflow_backend.clear_session() # destroys the current graph and builds a new one\nmodel=my_model() # create the model\nK.set_value(model.optimizer.lr,0.0005) # set the learning rate\n# fit the model\nh=model.fit(x=X_train,     \n            y=y_train, \n            batch_size=64, \n            epochs=20, \n            verbose=1, \n            validation_data=(X_test,y_test),\n            shuffle=True,\n            callbacks=[\n                ModelCheckpoint(filepath=path_model),\n            ]\n            )","execution_count":56,"outputs":[{"output_type":"stream","text":"Train on 32298 samples, validate on 3589 samples\nEpoch 1/20\n32298/32298 [==============================] - 16s 489us/step - loss: 1.6077 - acc: 0.3862 - val_loss: 1.4770 - val_acc: 0.4422\nEpoch 2/20\n32298/32298 [==============================] - 15s 454us/step - loss: 1.2286 - acc: 0.5342 - val_loss: 1.4312 - val_acc: 0.4547\nEpoch 3/20\n32298/32298 [==============================] - 15s 455us/step - loss: 1.0672 - acc: 0.6034 - val_loss: 1.2968 - val_acc: 0.5208\nEpoch 4/20\n32298/32298 [==============================] - 15s 462us/step - loss: 0.9412 - acc: 0.6529 - val_loss: 1.1060 - val_acc: 0.5890\nEpoch 5/20\n32298/32298 [==============================] - 14s 446us/step - loss: 0.8062 - acc: 0.7019 - val_loss: 1.1088 - val_acc: 0.5871\nEpoch 6/20\n32298/32298 [==============================] - 15s 458us/step - loss: 0.6650 - acc: 0.7577 - val_loss: 1.2096 - val_acc: 0.5748\nEpoch 7/20\n32298/32298 [==============================] - 15s 451us/step - loss: 0.4957 - acc: 0.8257 - val_loss: 1.4137 - val_acc: 0.5483\nEpoch 8/20\n32298/32298 [==============================] - 15s 454us/step - loss: 0.3274 - acc: 0.8911 - val_loss: 1.4580 - val_acc: 0.5826\nEpoch 9/20\n32298/32298 [==============================] - 15s 458us/step - loss: 0.2306 - acc: 0.9239 - val_loss: 1.4762 - val_acc: 0.6038\nEpoch 10/20\n32298/32298 [==============================] - 15s 468us/step - loss: 0.1694 - acc: 0.9470 - val_loss: 1.5534 - val_acc: 0.6071\nEpoch 11/20\n32298/32298 [==============================] - 15s 456us/step - loss: 0.1377 - acc: 0.9574 - val_loss: 1.6333 - val_acc: 0.6135\nEpoch 12/20\n32298/32298 [==============================] - 14s 449us/step - loss: 0.1145 - acc: 0.9650 - val_loss: 1.9442 - val_acc: 0.6027\nEpoch 13/20\n32298/32298 [==============================] - 14s 446us/step - loss: 0.1080 - acc: 0.9658 - val_loss: 1.9170 - val_acc: 0.5818\nEpoch 14/20\n32298/32298 [==============================] - 15s 456us/step - loss: 0.1089 - acc: 0.9647 - val_loss: 1.9758 - val_acc: 0.6004\nEpoch 15/20\n32298/32298 [==============================] - 15s 471us/step - loss: 0.0998 - acc: 0.9680 - val_loss: 1.9787 - val_acc: 0.6108\nEpoch 16/20\n32298/32298 [==============================] - 15s 451us/step - loss: 0.0832 - acc: 0.9731 - val_loss: 2.0155 - val_acc: 0.6077\nEpoch 17/20\n32298/32298 [==============================] - 15s 452us/step - loss: 0.0778 - acc: 0.9760 - val_loss: 2.2077 - val_acc: 0.5971\nEpoch 18/20\n32298/32298 [==============================] - 15s 450us/step - loss: 0.0778 - acc: 0.9757 - val_loss: 1.9966 - val_acc: 0.6074\nEpoch 19/20\n32298/32298 [==============================] - 15s 460us/step - loss: 0.0813 - acc: 0.9737 - val_loss: 2.2357 - val_acc: 0.6016\nEpoch 20/20\n32298/32298 [==============================] - 15s 451us/step - loss: 0.0847 - acc: 0.9708 - val_loss: 2.0200 - val_acc: 0.5985\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"path_model='model_filter.h5' # save model at this location after each epoch\nK.tensorflow_backend.clear_session() # destroys the current graph and builds a new one\nmodel=my_model() # create the model\nK.set_value(model.optimizer.lr,0.0001) # set the learning rate\n# fit the model\nh=model.fit(x=X_train,     \n            y=y_train, \n            batch_size=64, \n            epochs=50, \n            verbose=1, \n            validation_data=(X_test,y_test),\n            shuffle=True,\n            callbacks=[\n                ModelCheckpoint(filepath=path_model),\n            ]\n            )","execution_count":61,"outputs":[{"output_type":"stream","text":"Train on 32298 samples, validate on 3589 samples\nEpoch 1/50\n32298/32298 [==============================] - 16s 503us/step - loss: 1.6674 - acc: 0.3666 - val_loss: 1.5941 - val_acc: 0.3812\nEpoch 2/50\n32298/32298 [==============================] - 15s 454us/step - loss: 1.3793 - acc: 0.4773 - val_loss: 1.4977 - val_acc: 0.4129\nEpoch 3/50\n32298/32298 [==============================] - 15s 450us/step - loss: 1.2005 - acc: 0.5496 - val_loss: 1.3370 - val_acc: 0.4976\nEpoch 4/50\n32298/32298 [==============================] - 15s 458us/step - loss: 1.0390 - acc: 0.6197 - val_loss: 1.3124 - val_acc: 0.5085\nEpoch 5/50\n32298/32298 [==============================] - 15s 474us/step - loss: 0.8758 - acc: 0.6840 - val_loss: 1.2014 - val_acc: 0.5458\nEpoch 6/50\n32298/32298 [==============================] - 15s 455us/step - loss: 0.7167 - acc: 0.7482 - val_loss: 1.2551 - val_acc: 0.5313\nEpoch 7/50\n32298/32298 [==============================] - 15s 449us/step - loss: 0.5304 - acc: 0.8278 - val_loss: 1.2325 - val_acc: 0.5723\nEpoch 8/50\n32298/32298 [==============================] - 14s 447us/step - loss: 0.3676 - acc: 0.8944 - val_loss: 1.2720 - val_acc: 0.5740\nEpoch 9/50\n32298/32298 [==============================] - 15s 456us/step - loss: 0.2324 - acc: 0.9445 - val_loss: 1.3672 - val_acc: 0.5712\nEpoch 10/50\n32298/32298 [==============================] - 15s 475us/step - loss: 0.1526 - acc: 0.9688 - val_loss: 1.3917 - val_acc: 0.5740\nEpoch 11/50\n32298/32298 [==============================] - 14s 448us/step - loss: 0.1206 - acc: 0.9759 - val_loss: 1.4675 - val_acc: 0.5754\nEpoch 12/50\n32298/32298 [==============================] - 15s 455us/step - loss: 0.0946 - acc: 0.9825 - val_loss: 1.5175 - val_acc: 0.5729\nEpoch 13/50\n32298/32298 [==============================] - 15s 452us/step - loss: 0.0999 - acc: 0.9778 - val_loss: 1.6015 - val_acc: 0.5589\nEpoch 14/50\n32298/32298 [==============================] - 15s 462us/step - loss: 0.1078 - acc: 0.9719 - val_loss: 1.6548 - val_acc: 0.5687\nEpoch 15/50\n32298/32298 [==============================] - 15s 459us/step - loss: 0.0904 - acc: 0.9767 - val_loss: 1.6539 - val_acc: 0.5862\nEpoch 16/50\n32298/32298 [==============================] - 15s 467us/step - loss: 0.0741 - acc: 0.9819 - val_loss: 1.8317 - val_acc: 0.5729\nEpoch 17/50\n32298/32298 [==============================] - 15s 449us/step - loss: 0.0643 - acc: 0.9838 - val_loss: 1.8549 - val_acc: 0.5731\nEpoch 18/50\n32298/32298 [==============================] - 15s 463us/step - loss: 0.0770 - acc: 0.9786 - val_loss: 1.9094 - val_acc: 0.5575\nEpoch 19/50\n32298/32298 [==============================] - 14s 444us/step - loss: 0.0627 - acc: 0.9829 - val_loss: 1.9259 - val_acc: 0.5598\nEpoch 20/50\n32298/32298 [==============================] - 15s 454us/step - loss: 0.0705 - acc: 0.9801 - val_loss: 1.9124 - val_acc: 0.5712\nEpoch 21/50\n32298/32298 [==============================] - 15s 467us/step - loss: 0.0750 - acc: 0.9770 - val_loss: 2.0230 - val_acc: 0.5779\nEpoch 22/50\n32298/32298 [==============================] - 15s 465us/step - loss: 0.0625 - acc: 0.9821 - val_loss: 1.9180 - val_acc: 0.5648\nEpoch 23/50\n32298/32298 [==============================] - 15s 451us/step - loss: 0.0504 - acc: 0.9862 - val_loss: 1.9642 - val_acc: 0.5751\nEpoch 24/50\n32298/32298 [==============================] - 15s 449us/step - loss: 0.0522 - acc: 0.9852 - val_loss: 1.9892 - val_acc: 0.5575\nEpoch 25/50\n32298/32298 [==============================] - 15s 453us/step - loss: 0.0671 - acc: 0.9791 - val_loss: 2.1961 - val_acc: 0.5322\nEpoch 26/50\n32298/32298 [==============================] - 15s 466us/step - loss: 0.0573 - acc: 0.9828 - val_loss: 1.9679 - val_acc: 0.5740\nEpoch 27/50\n32298/32298 [==============================] - 15s 467us/step - loss: 0.0396 - acc: 0.9887 - val_loss: 1.9493 - val_acc: 0.5815\nEpoch 28/50\n32298/32298 [==============================] - 14s 449us/step - loss: 0.0420 - acc: 0.9874 - val_loss: 2.0330 - val_acc: 0.5815\nEpoch 29/50\n32298/32298 [==============================] - 15s 453us/step - loss: 0.0587 - acc: 0.9811 - val_loss: 2.0922 - val_acc: 0.5648\nEpoch 30/50\n32298/32298 [==============================] - 15s 458us/step - loss: 0.0608 - acc: 0.9799 - val_loss: 2.1170 - val_acc: 0.5776\nEpoch 31/50\n32298/32298 [==============================] - 15s 454us/step - loss: 0.0456 - acc: 0.9858 - val_loss: 2.0784 - val_acc: 0.5634\nEpoch 32/50\n32298/32298 [==============================] - 15s 459us/step - loss: 0.0355 - acc: 0.9893 - val_loss: 2.2294 - val_acc: 0.5773\nEpoch 33/50\n32298/32298 [==============================] - 15s 470us/step - loss: 0.0382 - acc: 0.9881 - val_loss: 2.3176 - val_acc: 0.5756\nEpoch 34/50\n32298/32298 [==============================] - 15s 459us/step - loss: 0.0491 - acc: 0.9842 - val_loss: 2.2679 - val_acc: 0.5495\nEpoch 35/50\n32298/32298 [==============================] - 15s 455us/step - loss: 0.0464 - acc: 0.9850 - val_loss: 2.1508 - val_acc: 0.5712\nEpoch 36/50\n32298/32298 [==============================] - 14s 446us/step - loss: 0.0436 - acc: 0.9855 - val_loss: 2.3337 - val_acc: 0.5704\nEpoch 37/50\n32298/32298 [==============================] - 15s 453us/step - loss: 0.0404 - acc: 0.9870 - val_loss: 2.2570 - val_acc: 0.5743\nEpoch 38/50\n32298/32298 [==============================] - 15s 478us/step - loss: 0.0412 - acc: 0.9869 - val_loss: 2.2441 - val_acc: 0.5756\nEpoch 39/50\n32298/32298 [==============================] - 15s 456us/step - loss: 0.0336 - acc: 0.9892 - val_loss: 2.3217 - val_acc: 0.5692\nEpoch 40/50\n32298/32298 [==============================] - 15s 450us/step - loss: 0.0355 - acc: 0.9876 - val_loss: 2.1924 - val_acc: 0.5720\nEpoch 41/50\n32298/32298 [==============================] - 14s 448us/step - loss: 0.0360 - acc: 0.9885 - val_loss: 2.2972 - val_acc: 0.5745\nEpoch 42/50\n32298/32298 [==============================] - 15s 466us/step - loss: 0.0337 - acc: 0.9895 - val_loss: 2.3720 - val_acc: 0.5734\nEpoch 43/50\n32298/32298 [==============================] - 15s 454us/step - loss: 0.0454 - acc: 0.9851 - val_loss: 2.4565 - val_acc: 0.5595\nEpoch 44/50\n32298/32298 [==============================] - 15s 467us/step - loss: 0.0381 - acc: 0.9874 - val_loss: 2.2003 - val_acc: 0.5818\nEpoch 45/50\n32298/32298 [==============================] - 15s 452us/step - loss: 0.0303 - acc: 0.9901 - val_loss: 2.3388 - val_acc: 0.5754\nEpoch 46/50\n32298/32298 [==============================] - 15s 468us/step - loss: 0.0333 - acc: 0.9884 - val_loss: 2.3134 - val_acc: 0.5754\nEpoch 47/50\n32298/32298 [==============================] - 14s 447us/step - loss: 0.0318 - acc: 0.9893 - val_loss: 2.1773 - val_acc: 0.5893\nEpoch 48/50\n32298/32298 [==============================] - 15s 453us/step - loss: 0.0334 - acc: 0.9890 - val_loss: 2.4228 - val_acc: 0.5790\nEpoch 49/50\n32298/32298 [==============================] - 15s 456us/step - loss: 0.0352 - acc: 0.9880 - val_loss: 2.4744 - val_acc: 0.5667\nEpoch 50/50\n32298/32298 [==============================] - 15s 475us/step - loss: 0.0371 - acc: 0.9869 - val_loss: 2.5187 - val_acc: 0.5801\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def my_model():\n    model = Sequential()\n    input_shape = (48,48,1)\n    model.add(Conv2D(64, (5, 5), input_shape=input_shape,activation='relu', padding='same'))\n    model.add(Conv2D(64, (5, 5), activation='relu', padding='same'))\n    model.add(BatchNormalization())\n    model.add(MaxPooling2D(pool_size=(2, 2)))\n    \n\n    model.add(Conv2D(128, (5, 5),activation='relu',padding='same'))\n    model.add(Conv2D(128, (5, 5),activation='relu',padding='same'))\n    model.add(BatchNormalization())\n    model.add(MaxPooling2D(pool_size=(2, 2)))\n    \n    model.add(Conv2D(256, (3, 3),activation='relu',padding='same'))\n    model.add(Conv2D(256, (3, 3),activation='relu',padding='same'))\n    model.add(BatchNormalization())\n    model.add(MaxPooling2D(pool_size=(2, 2)))\n\n    model.add(Flatten())\n    model.add(Dense(128))\n    model.add(BatchNormalization())\n    model.add(Activation('relu'))\n    model.add(Dropout(0.2))\n    model.add(Dense(7))\n    model.add(Activation('softmax'))\n    \n    model.compile(loss='categorical_crossentropy', metrics=['accuracy'],optimizer='adam')\n    # UNCOMMENT THIS TO VIEW THE ARCHITECTURE\n    model.summary()\n    \n    return model\nmodel=my_model()\nmodel.summary()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"path_model='model_filter(MAXPOOLING removed).h5' # save model at this location after each epoch\nK.tensorflow_backend.clear_session() # destroys the current graph and builds a new one\nmodel=my_model() # create the model\nK.set_value(model.optimizer.lr,1e-3) # set the learning rate\n# fit the model\nh=model.fit(x=X_train,     \n            y=y_train, \n            batch_size=64, \n            epochs=20, \n            verbose=1, \n            validation_data=(X_test,y_test),\n            shuffle=True,\n            callbacks=[\n                ModelCheckpoint(filepath=path_model),\n            ]\n            )","execution_count":68,"outputs":[{"output_type":"stream","text":"_________________________________________________________________\nLayer (type)                 Output Shape              Param #   \n=================================================================\nconv2d_1 (Conv2D)            (None, 48, 48, 64)        1664      \n_________________________________________________________________\nconv2d_2 (Conv2D)            (None, 48, 48, 64)        102464    \n_________________________________________________________________\nbatch_normalization_1 (Batch (None, 48, 48, 64)        256       \n_________________________________________________________________\nconv2d_3 (Conv2D)            (None, 48, 48, 128)       204928    \n_________________________________________________________________\nconv2d_4 (Conv2D)            (None, 48, 48, 128)       409728    \n_________________________________________________________________\nbatch_normalization_2 (Batch (None, 48, 48, 128)       512       \n_________________________________________________________________\nmax_pooling2d_1 (MaxPooling2 (None, 24, 24, 128)       0         \n_________________________________________________________________\nflatten_1 (Flatten)          (None, 73728)             0         \n_________________________________________________________________\ndense_1 (Dense)              (None, 128)               9437312   \n_________________________________________________________________\nbatch_normalization_3 (Batch (None, 128)               512       \n_________________________________________________________________\nactivation_1 (Activation)    (None, 128)               0         \n_________________________________________________________________\ndropout_1 (Dropout)          (None, 128)               0         \n_________________________________________________________________\ndense_2 (Dense)              (None, 7)                 903       \n_________________________________________________________________\nactivation_2 (Activation)    (None, 7)                 0         \n=================================================================\nTotal params: 10,158,279\nTrainable params: 10,157,639\nNon-trainable params: 640\n_________________________________________________________________\nTrain on 32298 samples, validate on 3589 samples\nEpoch 1/20\n32298/32298 [==============================] - 24s 758us/step - loss: 1.6063 - acc: 0.3810 - val_loss: 1.4474 - val_acc: 0.4505\nEpoch 2/20\n32298/32298 [==============================] - 23s 699us/step - loss: 1.2733 - acc: 0.5150 - val_loss: 1.3176 - val_acc: 0.4921\nEpoch 3/20\n32298/32298 [==============================] - 23s 710us/step - loss: 1.0315 - acc: 0.6165 - val_loss: 1.2989 - val_acc: 0.5194\nEpoch 4/20\n32298/32298 [==============================] - 23s 708us/step - loss: 0.7343 - acc: 0.7372 - val_loss: 1.3260 - val_acc: 0.5327\nEpoch 5/20\n32298/32298 [==============================] - 23s 697us/step - loss: 0.4167 - acc: 0.8649 - val_loss: 1.5324 - val_acc: 0.5461\nEpoch 6/20\n32298/32298 [==============================] - 23s 704us/step - loss: 0.2082 - acc: 0.9403 - val_loss: 1.7966 - val_acc: 0.5355\nEpoch 7/20\n32298/32298 [==============================] - 23s 701us/step - loss: 0.1258 - acc: 0.9674 - val_loss: 1.9616 - val_acc: 0.5500\nEpoch 8/20\n32298/32298 [==============================] - 23s 718us/step - loss: 0.0955 - acc: 0.9762 - val_loss: 2.2066 - val_acc: 0.5311\nEpoch 9/20\n32298/32298 [==============================] - 23s 698us/step - loss: 0.0869 - acc: 0.9782 - val_loss: 2.1666 - val_acc: 0.5316\nEpoch 10/20\n32298/32298 [==============================] - 22s 693us/step - loss: 0.0845 - acc: 0.9765 - val_loss: 2.1374 - val_acc: 0.5464\nEpoch 11/20\n32298/32298 [==============================] - 23s 720us/step - loss: 0.0783 - acc: 0.9781 - val_loss: 2.3189 - val_acc: 0.5417\nEpoch 12/20\n32298/32298 [==============================] - 23s 697us/step - loss: 0.0632 - acc: 0.9839 - val_loss: 2.2099 - val_acc: 0.5503\nEpoch 13/20\n32298/32298 [==============================] - 23s 697us/step - loss: 0.0592 - acc: 0.9848 - val_loss: 2.3860 - val_acc: 0.5464\nEpoch 14/20\n32298/32298 [==============================] - 23s 708us/step - loss: 0.0572 - acc: 0.9848 - val_loss: 2.7158 - val_acc: 0.5297\nEpoch 15/20\n32298/32298 [==============================] - 23s 710us/step - loss: 0.0567 - acc: 0.9849 - val_loss: 2.4176 - val_acc: 0.5428\nEpoch 16/20\n32298/32298 [==============================] - 23s 710us/step - loss: 0.0552 - acc: 0.9852 - val_loss: 2.2564 - val_acc: 0.5166\nEpoch 17/20\n32298/32298 [==============================] - 22s 695us/step - loss: 0.0517 - acc: 0.9859 - val_loss: 2.4541 - val_acc: 0.5450\nEpoch 18/20\n32298/32298 [==============================] - 23s 707us/step - loss: 0.0523 - acc: 0.9861 - val_loss: 2.8013 - val_acc: 0.5394\nEpoch 19/20\n32298/32298 [==============================] - 23s 715us/step - loss: 0.0465 - acc: 0.9877 - val_loss: 2.4863 - val_acc: 0.5311\nEpoch 20/20\n32298/32298 [==============================] - 23s 700us/step - loss: 0.0413 - acc: 0.9889 - val_loss: 2.3538 - val_acc: 0.5350\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"def my_model():\n    model = Sequential()\n    input_shape = (48,48,1)\n    model.add(Conv2D(64, (5, 5), input_shape=input_shape,activation='relu', padding='same'))\n    model.add(Conv2D(64, (5, 5), activation='relu', padding='same'))\n    model.add(BatchNormalization())\n    model.add(MaxPooling2D(pool_size=(2, 2)))\n\n    model.add(Conv2D(128, (5, 5),activation='relu',padding='same'))\n    model.add(Conv2D(128, (5, 5),activation='relu',padding='same'))\n    model.add(BatchNormalization())\n    model.add(MaxPooling2D(pool_size=(2, 2)))\n\n    model.add(Flatten())\n    model.add(Dense(128))\n    model.add(BatchNormalization())\n    model.add(Activation('relu'))\n    model.add(Dropout(0.2))\n    model.add(Dense(7))\n    model.add(Activation('softmax'))\n    \n    model.compile(loss='categorical_crossentropy', metrics=['accuracy'],optimizer='adam')\n    # UNCOMMENT THIS TO VIEW THE ARCHITECTURE\n    model.summary()\n    \n    return model\nmodel=my_model()\nmodel.summary()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"path_model='model_filter2.h5' # save model at this location after each epoch\nK.tensorflow_backend.clear_session() # destroys the current graph and builds a new one\nmodel=my_model() # create the model\nK.set_value(model.optimizer.lr,1e-3) # set the learning rate\n# fit the model\nh=model.fit(x=X_train,     \n            y=y_train, \n            batch_size=64, \n            epochs=20, \n            verbose=1, \n            validation_data=(X_test,y_test),\n            shuffle=True,\n            callbacks=[\n                ModelCheckpoint(filepath=path_model),\n            ]\n            )","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Activation layer 'selu'"},{"metadata":{"trusted":true},"cell_type":"code","source":"def my_model2():\n    model = Sequential()\n    input_shape = (48,48,1)\n    model.add(Conv2D(64, (5, 5), input_shape=input_shape,activation='selu', padding='same'))\n    model.add(Conv2D(64, (5, 5), activation='selu', padding='same'))\n    model.add(BatchNormalization())\n    model.add(MaxPooling2D(pool_size=(2, 2)))\n\n    model.add(Conv2D(128, (5, 5),activation='selu',padding='same'))\n    model.add(Conv2D(128, (5, 5),activation='selu',padding='same'))\n    model.add(BatchNormalization())\n    model.add(MaxPooling2D(pool_size=(2, 2)))\n\n    model.add(Conv2D(256, (3, 3),activation='selu',padding='same'))\n    model.add(Conv2D(256, (3, 3),activation='selu',padding='same'))\n    model.add(BatchNormalization())\n    model.add(MaxPooling2D(pool_size=(2, 2)))\n\n    model.add(Flatten())\n    model.add(Dense(128))\n    model.add(BatchNormalization())\n    model.add(Activation('selu'))\n    model.add(Dropout(0.2))\n    model.add(Dense(7))\n    model.add(Activation('softmax'))\n    \n    model.compile(loss='categorical_crossentropy', metrics=['accuracy'],optimizer='adam')\n    # UNCOMMENT THIS TO VIEW THE ARCHITECTURE\n    #model.summary()\n    \n    return model\nmodel=my_model()\nmodel.summary()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"path_model='model_filter1.h5' # save model at this location after each epoch\nK.tensorflow_backend.clear_session() # destroys the current graph and builds a new one\nmodel=my_model() # create the model\nK.set_value(model.optimizer.lr,1e-3) # set the learning rate\n# fit the model\nh=model.fit(x=X_train,     \n            y=y_train, \n            batch_size=64, \n            epochs=20, \n            verbose=1, \n            validation_data=(X_test,y_test),\n            shuffle=True,\n            callbacks=[\n                ModelCheckpoint(filepath=path_model),\n            ]\n            )","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"0c7e2abb2a89f4df0d28de0a49db1f60c84fbcf0"},"cell_type":"code","source":"objects = ('angry', 'disgust', 'fear', 'happy', 'sad', 'surprise', 'neutral')\ny_pos = np.arange(len(objects))\nprint(y_pos)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"077d44e8bbb7549a09682eb09c417903bf2fd935"},"cell_type":"code","source":"def emotion_analysis(emotions):\n    objects = ['angry', 'disgust', 'fear', 'happy', 'sad', 'surprise', 'neutral']\n    y_pos = np.arange(len(objects))\n    plt.bar(y_pos, emotions, align='center', alpha=0.9)\n    plt.tick_params(axis='x', which='both', pad=10,width=4,length=10)\n    plt.xticks(y_pos, objects)\n    plt.ylabel('percentage')\n    plt.title('emotion')\n    \nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"241291244491cc1e84a45ecb0da66c1c09a4cd7a"},"cell_type":"code","source":"y_pred=model.predict(X_test)\n#print(y_pred)\ny_test.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"0e97d2cb00640d2bfc4d4de9456249e893f72cc2"},"cell_type":"code","source":"#import seaborn as sn\n#import pandas as pd\n#import matplotlib.pyplot as plt\n#import numpy as np\n#from sklearn.metrics import confusion_matrix\n#%matplotlib inline\n#cm = confusion_matrix(np.where(y_test == 1)[1], y_pred)\n#cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n#df_cm = pd.DataFrame(cm, index = [i for i in \"0123456\"],\n                  #columns = [i for i in \"0123456\"])\n#plt.figure(figsize = (20,15))\n#sn.heatmap(df_cm, annot=True)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Real Time Expression Prediction**"},{"metadata":{"trusted":true,"_uuid":"70fc48e66d18c54ba629e625ad8def5ad2d93fa6"},"cell_type":"code","source":"from skimage import io\nimg = image.load_img('../input/myimage/Shawon.jpg', grayscale=True, target_size=(48, 48))\nshow_img=image.load_img('../input/myimage/Shawon.jpg', grayscale=False, target_size=(200, 200))\nx = image.img_to_array(img)\nx = np.expand_dims(x, axis = 0)\n\nx /= 255\n\ncustom = model.predict(x)\n#print(custom[0])\nemotion_analysis(custom[0])\n\nx = np.array(x, 'float32')\nx = x.reshape([48, 48]);\n\nplt.gray()\nplt.imshow(show_img)\nplt.show()\n\nm=0.000000000000000000001\na=custom[0]\nfor i in range(0,len(a)):\n    if a[i]>m:\n        m=a[i]\n        ind=i\n        \nprint('Expression Prediction:',objects[ind])\n        ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"82db72b60f80eb18474bf880369791cf346c9749"},"cell_type":"code","source":"from skimage import io\nimg = image.load_img('../input/testimages/wallpaper2you_443897.jpg', grayscale=True, target_size=(48, 48))\nshow_img=image.load_img('../input/testimages/wallpaper2you_443897.jpg', grayscale=False, target_size=(200, 200))\nx = image.img_to_array(img)\nx = np.expand_dims(x, axis = 0)\n\nx /= 255\n\ncustom = model.predict(x)\n#print(custom[0])\nemotion_analysis(custom[0])\n\nx = np.array(x, 'float32')\nx = x.reshape([48, 48]);\n\nplt.gray()\nplt.imshow(show_img)\nplt.show()\n\nm=0.000000000000000000001\na=custom[0]\nfor i in range(0,len(a)):\n    if a[i]>m:\n        m=a[i]\n        ind=i\n        \nprint('Expression Prediction:',objects[ind])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Live Demo of Production Level Project**\n\n[Facial Expression Detection Web App](https://faceai.herokuapp.com/)"}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}